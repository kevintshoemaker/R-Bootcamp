into = c("Station","climvar")
)
clim_vars_separate
# step 3: pivot_wider distributes the clim_var column into separate columns, with the data values from the 'value' column
tidy_clim_data <- clim_vars_separate %>% pivot_wider(
names_from = climvar,
values_from = value
)
tidy_clim_data
# repeat above as single pipe series without creation of intermediate datasets
tidy_clim_data <- clim_data %>%
pivot_longer(cols = !Date,
names_to = "climvar_station",
values_to = "value") %>%
separate(col = climvar_station,
into = c("Station","climvar")) %>%
pivot_wider(names_from = climvar,
values_from = value)
tidy_clim_data
#  Use dplyr verbs to wrangle data   ----------------------------
# example of simple data selection and summary using group_by, summarize, and mutate verbs
# take tidy_clim_data, then
# group data by station, then
# calculate summaries and put in columns with names mean.precip.in, mean.TMax.F, and mean.Tmin.F, then
# transform to metric and put in new columns mean.precip.in, mean.TMax.F, and mean.Tmin.F
station_mean1 <- tidy_clim_data %>%
group_by(Station) %>%
summarize(
mean.precip.in = mean(PrcpIN, na.rm=TRUE),
mean.TMax.F = mean(TMaxF, na.rm=TRUE),
mean.TMin.F = mean(TMinF, na.rm=TRUE)) %>%
mutate(
mean.precip.mm = mean.precip.in * 25.4,
mean.TMax.C = (mean.TMax.F - 32) * 5 / 9,
mean.TMin.C = (mean.TMin.F - 32) * 5 / 9
)
station_mean1
# using an even more compact form:
# take tidy_clim_data, then
# group data by station, then
# calculate summary (mean of all non-NA values) for numeric data only, then
# transform temp data (.) from F to C, then
# transform precip data (.) from in to mm
station_mean2 <- tidy_clim_data %>%
group_by(Station) %>%
summarize(across(where(is.numeric), mean, na.rm=TRUE)) %>%
mutate(across(c("TMaxF", "TMinF"), ~(.-32)*(5/9)))   %>%
rename_with(~gsub("F","C",.),starts_with("T")) %>%
mutate(across(PrcpIN, ~.*25.4,.names="Prcp_mm")) %>%
select(!PrcpIN)
station_mean2
#  Using lubridate to format and create date data types -----------------
library(lubridate)
date_string <- ("2017-01-31")
# convert date string into date format by identifing the order in which
#   year, month, and day appear in your dates, then arrange "y", "m", and #   "d" in the same order. That gives you the name of the lubridate
#    function that will parse your date
ymd(date_string)
# note the different formats of the date_string and date_dtformat objects in the environment window.
# a variety of other formats/orders can also be accommodated. Note how each of these are reformatted to "2017-01-31" A timezone can be specified using tz=
mdy("January 31st, 2017")
dmy("31-Jan-2017")
ymd(20170131)
ymd(20170131, tz = "UTC")
# can also make a date from components.
#   this is useful if you have columns for year, month,
#   day in a dataframe
year<-2017
month<-1
day<-31
make_date(year, month, day)
# times can be included as well. Note that unless otherwise specified, R assumes UTC time
ymd_hms("2017-01-31 20:11:59")
mdy_hm("01/31/2017 08:01")
# we can also have R tell us the current time or date
now()
today()
#  Parsing dates with lubridate -----------------------
datetime <- ymd_hms("2016-07-08 12:34:56")
# year
year(datetime)
# month as numeric
month(datetime)
# month as name
month(datetime, label = TRUE)
# day of month
mday(datetime)
# day of year (julian day)
yday(datetime)
# day of week
wday(datetime)
wday(datetime, label = TRUE, abbr = FALSE)
####  Using lubridate with dataframes and dplyr verbs
# going back to our tidy_clim_data dataset we see that
#   the date column is formatted as character, not date
head(tidy_clim_data)
# change format of date column
tidy_clim_data <- tidy_clim_data %>%
mutate(Date = mdy(Date))
tidy_clim_data
# parse date into year, month, day, and day of year columns
tidy_clim_data <- tidy_clim_data %>%
mutate(
Year = year(Date),
Month = month(Date),
Day = mday(Date),
Yday = yday(Date)
)
tidy_clim_data
# calculate total annual precipitation by station and year
annual_sum_precip_by_station <- tidy_clim_data %>%
group_by(Station, Year) %>%
summarise(PrecipSum = sum(PrcpIN))
annual_sum_precip_by_station
relig_income %>%
pivot_longer(cols=!religion, names_to = "Income",values_to="count")
# CHALLENGE EXERCISES   -------------------------------------
# 1. Try to put tidyr's built-in `relig_income` dataset into a tidier format.
#      This dataset stores counts based on a survey which (among other things)
#      asked people about their religion and annual income:
# 2. Use the dplyr verbs and the tidy_clim_data dataset you created above
#       to calculate monthly average Tmin and Tmax for each station
# 3. Using lubridate, make a date object out of a character string of your
#        birthday and find the day of year it occurred on.
tidy_clim_data
?summarize_at
tidy_clim_data %>%
group_by(Station,Month) %>%
summarize(across(c(Tmin,Tmax),mean))
tidy_clim_data
tidy_clim_data %>%
group_by(Station,Month) %>%
summarize(across(c(TminF,TmaxF),mean))
tidy_clim_data
tidy_clim_data %>%
group_by(Station,Month) %>%
summarize(across(c(TMinF,TMaxF),mean))
mdy(mybday)
mybday <- "12/12/1977"
mdy(mybday)
day(mybday)
yday(mybday)
wday(mybday)
?wday
wday(mybday,label=T)
knitr::opts_chunk$set(echo = TRUE)
rmd2rscript <- function(infile="module1_1.Rmd"){    # function for converting markdown to scripts
outfile1 <- gsub(".Rmd",".R",infile)
outfile2 <- gsub(".Rmd",".txt",infile)
close( file( outfile1, open="w" ) )   # clear output file
close( file( outfile2, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile1,"w")
con3 <- file(outfile2,"w")
stringToFind <- "```{r*"
isrblock <- FALSE
count=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
if(isrblock){
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if(count>1){
write(newline,file=con2,append=TRUE)
write(newline,file=con3,append=TRUE)
}
count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript2 <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript2("module1_1.Rmd")
rmd2rscript2("module1_2.Rmd")
rmd2rscript2("module1_3.Rmd")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
mfv
library(modeest)
mfv
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
# lets find the most frequent value(s) in the "Export" column:
mfv(newdf$Export, na.rm = T)
newdf <- read.table(file="data_missing.txt", sep="\t", header=T)
# lets find the most frequent value(s) in the "Export" column:
mfv(newdf$Export, na.rm = T)
newdf$Export
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
cache = TRUE
)
#  R Bootcamp #2, Submodule 2.1 --------------------------
#   University of Nevada, Reno
#   Expanding R functionality: packages etc.
library(modeest)    # load the package: This is package 'modeest' written by P. PONCET.
newdf <- read.table(file="data_missing.txt", sep="\t", header=T)
# ?mlv   ?mfv # learn more about the functions for computing the mode (most likely value or most frequent value). Who knew there were so many methods for computing the mode?
# lets find the most frequent value(s) in the "Export" column:
mfv(newdf$Export, na.rm = T)
detach("package:modeest")  # remove the package from your current working session
# 3D Plotting example ---------------
#########
# Data: dog barks per day (and two explanatory variables)
Cars= c(32, 28, 9, 41, 23, 26, 26, 31, 12, 25, 32, 13, 19, 19, 38,
36, 43, 26, 21, 15, 17, 12, 7, 41, 38, 33, 31, 9, 40, 21)
Food= c(0.328, 0.213, 0.344, 0.339, 0.440, 0.335, 0.167, 0.440, 0.328,
0.100, 0.381, 0.175, 0.238, 0.360, 0.146, 0.430, 0.446, 0.345,
0.199, 0.301, 0.417, 0.409, 0.142, 0.301, 0.305, 0.230, 0.118,
0.272, 0.098, 0.415)
Bark=c(15, 14, 6, 12, 8, 1, 9, 8, 1, 12, 14, 9, 8, 1, 19, 8, 13, 9,
15, 11, 8, 7, 8, 16, 15, 10, 15, 4, 17, 0)
library(car)
Cars= c(32, 28, 9, 41, 23, 26, 26, 31, 12, 25, 32, 13, 19, 19, 38,
36, 43, 26, 21, 15, 17, 12, 7, 41, 38, 33, 31, 9, 40, 21)
Food= c(0.328, 0.213, 0.344, 0.339, 0.440, 0.335, 0.167, 0.440, 0.328,
0.100, 0.381, 0.175, 0.238, 0.360, 0.146, 0.430, 0.446, 0.345,
0.199, 0.301, 0.417, 0.409, 0.142, 0.301, 0.305, 0.230, 0.118,
0.272, 0.098, 0.415)
Bark=c(15, 14, 6, 12, 8, 1, 9, 8, 1, 12, 14, 9, 8, 1, 19, 8, 13, 9,
15, 11, 8, 7, 8, 16, 15, 10, 15, 4, 17, 0)
car::scatter3d(Bark~Food+Cars,surface=TRUE)
library(rgl)
install.packages("rgl")
car::scatter3d(Bark~Food+Cars,surface=TRUE)
# install.packages("remotes")    # run this if you haven't already installed the "remotes" package
library(remotes)
install.packages("remotes")
# install.packages("remotes")    # run this if you haven't already installed the "remotes" package
library(remotes)
install_github("kbroman/broman")  # install a random package from GitHub!
browseVignettes('dismo')
install.packages("dismo")
browseVignettes('dismo')
vignette('sdm','dismo')      # pull up one of the helpful vignettes from the 'dismo' package, with useful code examples! Many packages have built-in vignettes.
vignette('brt','dismo')      # and another one!
vignette('brt','dismo')      # and another one!
vignette('brt','dismo')
help.start()
citation('car')   # citation for the 'car' package
rmd2rscript <- function(infile="module1_1.Rmd"){    # function for converting markdown to scripts
outfile1 <- gsub(".Rmd",".R",infile)
outfile2 <- gsub(".Rmd",".txt",infile)
close( file( outfile1, open="w" ) )   # clear output file
close( file( outfile2, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile1,"w")
con3 <- file(outfile2,"w")
stringToFind <- "```{r*"
isrblock <- FALSE
count=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
if(isrblock){
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if(count>1){
write(newline,file=con2,append=TRUE)
write(newline,file=con3,append=TRUE)
}
count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript2 <- function(infile="LECTURE2.Rmd"){    # function for converting markdown to scripts
outfile <- gsub(".Rmd",".R",infile)
close( file( outfile, open="w" ) )   # clear output file
con1 <- file(infile,open="r")
con2 <- file(outfile,"w")
stringToFind <- "```{r*"
stringToFind2 <- "echo"
isrblock <- FALSE
#count=0
blocknum=0
while(length(input <- readLines(con1, n=1)) > 0){   # while there are still lines to be read
isrblock <- grepl(input, pattern = stringToFind, perl = TRUE)   # is it the start of an R block?
showit <- !grepl(input, pattern = stringToFind2, perl = TRUE)   # is it hidden (echo=FALSE)
if(isrblock){
blocknum=blocknum+1
while(!grepl(newline<-readLines(con1, n=1),pattern="```",perl=TRUE)){
if((blocknum>1)&((showit)|(blocknum==2))) write(newline,file=con2,append=TRUE)
#count=count+1
}
isrblock=FALSE
}
}
closeAllConnections()
}
rmd2rscript2("module1_1.Rmd")
rmd2rscript2("module1_1.Rmd")
rmd2rscript2("module1_2.Rmd")
rmd2rscript2("module1_2.Rmd")
rmd2rscript2("module1_3.Rmd")
rmd2rscript2("module1_4.Rmd")
rmd2rscript2("module1_4.Rmd")
rmd2rscript2("module2_1.Rmd")
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, message = FALSE)
## n is the number of animals being monitored.
## d is the number of animals that died.
survival <- function(n, d){
(n-d)/n
}
## One year of data.
survival(n = 10, d = 5)
## Simulate many years of data.
d <- sample(0:50, 10, replace = TRUE)   # note use of "sample()" function   [random number of dead individuals]
n <- rep(100, times=10)                 # total number of individuals
surv <- survival(n = n, d = d)
surv
## Plot year-specific survival rate (random- will look different every time!)
plot(1:10, surv, type = 'l',xlab="Year",ylab="Survival")
## Sequence between 0 and 1.
x <- seq(from = 0, to = 1, by = 0.01)
logit.x <- logit(x)
## The expit (or inverse logit) funtion.
expit <- function(x){
exp(x)/(1+exp(x))
}
## Calculate the inverse-logit of logit(0.9) = 2.197225.
expit(2.197225)
expit.logit.x <- expit(logit.x)    # Return to original x values.
## Plot x on x-axis, and expit(logit(x)) = x on y axis.
plot(x, expit.logit.x, type = 'l',xlab="x",ylab="expit(logit(x))")
## Plot "logistic" curve
plot(x=seq(-3,3,0.1),y=expit(seq(-3,3,0.1)),type="l",xlab="x",ylab="expit(x)")
## n is the number of animals being monitored.
## d is the number of animals that died.
survival <- function(n, d){
(n-d)/n
}
## One year of data.
survival(n = 10, d = 5)
## Simulate many years of data.
d <- sample(0:50, 10, replace = TRUE)   # note use of "sample()" function   [random number of dead individuals]
n <- rep(100, times=10)                 # total number of individuals
surv <- survival(n = n, d = d)
surv
## Plot year-specific survival rate (random- will look different every time!)
plot(1:10, surv, type = 'l',xlab="Year",ylab="Survival")
#  if...else statements -----------------------
# Draw a sample from a Binomial distribution with p = 0.7 (here, p is detection probability).
p <- 0.7            # probability of detection
x <- rbinom(n = 1, size = 1, prob = p)      # single 'coin flip' with prob success equal to p
if (x > 0) {
print("detected")
} else {
print("not detected")
}
## Clean-up data using "ifelse()" function
NewObs <- ifelse( (Data[, 1:3] == "Detected") | (Data[, 1:3] == "1"), 1, 0) #  The "|" means "or." Similarly "&" means "and"
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning = FALSE, message = FALSE)
#  R Bootcamp #1, submodule 2.2 ---------------------------
#    University of Nevada, Reno
#    PROGRAMMING: FUNCTIONS AND MORE
# Start with blank workspace -------------------
rm(list=ls())
## We can write our own functions. Useful if we have to repeat the same operations over and over with different inputs.
my.mean <- function(x){       # 'x' is the function argument- 'x' stands in for whatever numeric vector the user wants
m <- sum(x)/length(x)
return(m)
}
foo <- c(2, 4, 6, 8)
my.mean(foo)
## A function to square the arguments.
square <- function(x){
x^2
}
## Square a single value (scalar).
square(2)
## Square all elements of a vector.
square(1:10)
## Often, we need to write functions that are not included in the base R package e.g., the logit function.
## Calculate the log-odds (logit).
logit <- function(x){
log(x/(1-x))
}
## Calculate logit of 0.9.
logit(.9)
## Sequence between 0 and 1.
x <- seq(from = 0, to = 1, by = 0.01)
## Caclulate the logit of a vector.
logit.x <- logit(x)
logit.x
## Plot x on x-axis, and logit(x) on y axis.
plot(x, logit.x, type = 'l',xlab="x",ylab="logit(x)")    # View the output graphically.
## Sequence between 0 and 1.
x <- seq(from = 0, to = 1, by = 0.01)
logit.x <- logit(x)
## The expit (or inverse logit) funtion.
expit <- function(x){
exp(x)/(1+exp(x))
}
## Calculate the inverse-logit of logit(0.9) = 2.197225.
expit(2.197225)
expit.logit.x <- expit(logit.x)    # Return to original x values.
## Plot x on x-axis, and expit(logit(x)) = x on y axis.
plot(x, expit.logit.x, type = 'l',xlab="x",ylab="expit(logit(x))")
## Plot "logistic" curve
plot(x=seq(-3,3,0.1),y=expit(seq(-3,3,0.1)),type="l",xlab="x",ylab="expit(x)")
## n is the number of animals being monitored.
## d is the number of animals that died.
survival <- function(n, d){
(n-d)/n
}
## One year of data.
survival(n = 10, d = 5)
## Simulate many years of data.
d <- sample(0:50, 10, replace = TRUE)   # note use of "sample()" function   [random number of dead individuals]
n <- rep(100, times=10)                 # total number of individuals
surv <- survival(n = n, d = d)
surv
## Plot year-specific survival rate (random- will look different every time!)
plot(1:10, surv, type = 'l',xlab="Year",ylab="Survival")
#  if...else statements -----------------------
# Draw a sample from a Binomial distribution with p = 0.7 (here, p is detection probability).
p <- 0.7            # probability of detection
x <- rbinom(n = 1, size = 1, prob = p)      # single 'coin flip' with prob success equal to p
if (x > 0) {
print("detected")
} else {
print("not detected")
}
#  ifelse()  --------------------------------
## Note if...else only works for running one logical (T/F) test at a time. If we have a spreadsheet with lots of data, we need something else.
n.samples <- 100
set.seed(2017)     # the 'seed' allows random number generators to give the same result every time!
## 100 samples from a binomial distribution with detection probability p = 0.7.
y <- rbinom(n = n.samples, size = 1, prob = p)
y
## incorrect usage
if (y == 1) {
print("Detected")
} else {
print("Not detected")
}   # PRINTS A WARNING MESSAGE!
## Clean-up data using "ifelse()" function
NewObs <- ifelse( (Data[, 1:3] == "Detected") | (Data[, 1:3] == "1"), 1, 0) #  The "|" means "or." Similarly "&" means "and"
# Clean up messy matrix using ifelse  ---------------
## Simulate data.
observations <- matrix(sample(c("Detected", "NotDetected", 1, 0), 20*3, replace = TRUE), 20, 3)    # simulate detection/non-detection data over three sampling occasions
habitat <- rnorm(20, 0, 2)    # simulate environmental covariate
Data <- cbind(observations, habitat)       # bind into single matrix.
Data
## Clean-up data using "ifelse()" function
NewObs <- ifelse( (Data[, 1:3] == "Detected") | (Data[, 1:3] == "1"), 1, 0) #  The "|" means "or." Similarly "&" means "and"
NewHabitat <- as.numeric(Data[, 4])  # as.numeric gets rid of quotes around habitat data.
NewHabitat <- round(NewHabitat, 2)   # round rounds to number of decimals specified.
NewData <- cbind(NewObs, NewHabitat) # bind the columns to form a matrix.
colnames(NewData) <- c("obs1", "obs2", "obs3", "Habitat")  # provide column names
NewData
#  if...else statements -----------------------
# Draw a sample from a Binomial distribution with p = 0.7 (here, p is detection probability).
p <- 0.7            # probability of detection
x <- rbinom(n = 1, size = 1, prob = p)      # single 'coin flip' with prob success equal to p
if (x > 0) {
print("detected")
} else {
print("not detected")
}
#  ifelse()  --------------------------------
## Note if...else only works for running one logical (T/F) test at a time. If we have a spreadsheet with lots of data, we need something else.
n.samples <- 100
set.seed(2017)     # the 'seed' allows random number generators to give the same result every time!
## 100 samples from a binomial distribution with detection probability p = 0.7.
y <- rbinom(n = n.samples, size = 1, prob = p)
y
## incorrect usage
if (y == 1) {
print("Detected")
} else {
print("Not detected")
}   # PRINTS A WARNING MESSAGE!
#  if...else statements -----------------------
# Draw a sample from a Binomial distribution with p = 0.7 (here, p is detection probability).
p <- 0.7            # probability of detection
x <- rbinom(n = 1, size = 1, prob = p)      # single 'coin flip' with prob success equal to p
if (x > 0) {
print("detected")
} else {
print("not detected")
}
